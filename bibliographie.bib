
@article{gusev_using_2021,
	title = {Using {Modern} {Chess} {Software} for {Opening} {Preparation}},
	url = {https://eric.ed.gov/?id=ED617407},
	abstract = {A wide variety of modern chess software products is available to the modern professional and amateur chess players alike, helping them improve their chess skills and prepare for online and traditional tournaments. These products include chess user interfaces (UIs), traditional Alpha-Beta (AB) and emergent Neural Network (NN) chess engines, game databases, opening databases and electronic books, chess-specific cloud services, tournament broadcast tools, online tutorials, tactical problem collections, and endgame tablebases (EGTBs). All of these tools except the last two categories can be used to work on opening preparation, an important component of chess training. In this paper, the author presents his computer-based approach to opening preparation tested in chess classes at the Russian School of Indiana for advanced beginner players. The materials used to develop the approach included game openings from the games played in the Free Open-Source Chess Engine Contest (FOSCEC) broadcast online by the author’s CIT students at Purdue Polytechnic Columbus. We will discuss the choices of tools and equipment, how the more popular and/or promising opening variations were identified and analyzed, the lessons learned, and the future work.},
	language = {en},
	author = {Gusev, Dmitri A},
	year = {2021},
	file = {PDF:C\:\\Users\\marvi\\Zotero\\storage\\LFWFP4VF\\Gusev - 2021 - Using Modern Chess Software for Opening Preparation.pdf:application/pdf},
}

@article{gobet_training_2006,
	title = {Training in chess: {A} scientific approach},
	journal = {Chess and education},
	author = {Gobet, Fernand and Jansen, Peter},
	month = jan,
	year = {2006},
	file = {PDF:C\:\\Users\\marvi\\Zotero\\storage\\FSWE5CKU\\Gobet und Jansen - Training in chess A scientific approach.PDF:application/pdf},
}

@book{kron_grundwissen_2024,
	address = {Stuttgart},
	edition = {7., vollständig überarbeitete und erweiterte Auflage},
	series = {{UTB}},
	title = {Grundwissen {Didaktik}},
	isbn = {978-3-8252-8802-0 978-3-8385-8802-5 978-3-8463-8802-0},
	abstract = {Das Standardwerk zur Didaktik für Studierende erziehungswissenschaftlicher Fächer. Dieses Lehrbuch bietet eine verständlich geschriebene, wissenschaftliche Grundlage der Didaktik für Schule und außerschulische Bildungsbereiche. Zentral sind die Kapitel über didaktische Theorien, Modelle und Konzepte sowie über Lerntheorien. Das Lehrbuch eignet sich hervorragend als Informationsquelle und Nachschlagewerk für Prüfungsvorbereitungen aller Fachbereiche mit hohem Anteil an Didaktik},
	language = {ger},
	number = {8073},
	publisher = {Ernst Reinhardt Verlag},
	author = {Kron, Friedrich W. and Jürgens, Eiko and Standop, Jutta},
	year = {2024},
	doi = {10.36198/9783838588025},
	file = {2024-3-lerntheorien-und-modelle-im-kontext-von-lehren-und-lernen:C\:\\Users\\marvi\\Zotero\\storage\\5JLZP23L\\2024-3-lerntheorien-und-modelle-im-kontext-von-lehren-und-lernen.pdf:application/pdf},
}

@article{chesscom_chesscom_2022,
	title = {Chess.com hat 100 {Millionen} {Mitglieder}},
	url = {https://www.chess.com/de/article/view/chess-com-hat-100-millionen-mitglieder},
	urldate = {2024-11-03},
	author = {Chess.com},
	month = dec,
	year = {2022},
	file = {PDF:C\:\\Users\\marvi\\Zotero\\storage\\695M6XLH\\Chess.com - 2022 - Chess.com hat 100 Millionen Mitglieder.pdf:application/pdf},
}

@article{gobet_templates_1996,
	title = {Templates in {Chess} {Memory}: {A} {Mechanism} for {Recalling} {Several} {Boards}},
	volume = {31},
	issn = {0010-0285},
	url = {https://www.sciencedirect.com/science/article/pii/S0010028596900110},
	doi = {https://doi.org/10.1006/cogp.1996.0011},
	abstract = {This paper addresses empirically and theoretically a question derived from the chunking theory of memory (Chase \& Simon, 1973a, 1973b): To what extent is skilled chess memory limited by the size of short-term memory (about seven chunks)? This question is addressed first with an experiment where subjects, ranking from class A players to grandmasters, are asked to recall up to five positions presented during 5 s each. Results show a decline of percentage of recall with additional boards, but also show that expert players recall more pieces than is predicted by the chunking theory in its original form. A second experiment shows that longer latencies between the presentation of boards facilitate recall. In a third experiment, a Chessmaster gradually increases the number of boards he can reproduce with higher than 70\% average accuracy to nine, replacing as many as 160 pieces correctly. To account for the results of these experiments, a revision of the Chase–Simon theory is proposed. It is suggested that chess players, like experts in other recall tasks, use long-term memory retrieval structures (Chase \& Ericsson, 1982) or templates in addition to chunks in short-term memory to store information rapidly.},
	number = {1},
	journal = {Cognitive Psychology},
	author = {Gobet, Fernand and Simon, Herbert A.},
	year = {1996},
	pages = {1--40},
	file = {PDF:C\:\\Users\\marvi\\Zotero\\storage\\E8MG5VR4\\Gobet und Simon - 1996 - Templates in Chess Memory A Mechanism for Recalling Several Boards.pdf:application/pdf},
}

@article{knuth_analysis_1975,
	title = {An analysis of alpha-beta pruning},
	volume = {6},
	issn = {0004-3702},
	url = {https://www.sciencedirect.com/science/article/pii/0004370275900193},
	doi = {https://doi.org/10.1016/0004-3702(75)90019-3},
	abstract = {The alpha-beta technique for searching game trees is analyzed, in an attempt to provide some insight into its behavior. The first portion of this paper is an expository presentation of the method together with a proof of its correctness and a historical discussion. The alpha-beta procedure is shown to be optimal in a certain sense, and bounds are obtained for its running time with various kinds of random data.},
	number = {4},
	journal = {Artificial Intelligence},
	author = {Knuth, Donald E. and Moore, Ronald W.},
	year = {1975},
	pages = {293--326},
	file = {PDF:C\:\\Users\\marvi\\Zotero\\storage\\SMMRFDYG\\Knuth und Moore - 1975 - An analysis of alpha-beta pruning.pdf:application/pdf},
}

@article{vjekoslav_nemec_history_2019,
	title = {History {Of} {Chess} {Computer} {Engines}},
	url = {https://chessentials.com/history-of-chess-computer-engines/},
	urldate = {2024-11-23},
	author = {{Vjekoslav Nemec}},
	month = jan,
	year = {2019},
	file = {PDF:C\:\\Users\\marvi\\Zotero\\storage\\Q7KXM3SM\\Vjekoslav Nemec - 2019 - History Of Chess Computer Engines.pdf:application/pdf},
}

@article{baudet_branching_1978,
	title = {On the branching factor of the alpha-beta pruning algorithm},
	volume = {10},
	issn = {0004-3702},
	url = {https://www.sciencedirect.com/science/article/pii/S0004370278800113},
	doi = {https://doi.org/10.1016/S0004-3702(78)80011-3},
	abstract = {An analysis of the alpha-beta pruning algorithm is presented which takes into account both shallow and deep cut-offs. A formula is first developed to measure the average number of terminal nodes examined by the algorithm in a uniform tree of degree n and depth d when ties are allowed among the bottom positions: specifically, all bottom values are assumed to be independent identically distributed random variables drawn from a discrete probability distribution. A worst case analysis over all possible probability distributions is then presented by considering the limiting case when the discrete probability distribution tends to a continuous probability distribution. The branching factor of the alpha-beta pruning algorithm is shown to grow with n as Θ(n/lnn), therefore confirming a claim by Knuth and Moore that deep cut-offs only have a second order effect on the behavior of the algorithm.},
	number = {2},
	journal = {Artificial Intelligence},
	author = {Baudet, Gérard M.},
	year = {1978},
	pages = {173--199},
	file = {PDF:C\:\\Users\\marvi\\Zotero\\storage\\NMIMNRWQ\\Baudet - 1978 - On the branching factor of the alpha-beta pruning algorithm.pdf:application/pdf},
}
